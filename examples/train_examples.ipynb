{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cc633a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA\n",
    "import torch\n",
    "\n",
    "N = 100\n",
    "T = 12\n",
    "\n",
    "D1 = 5\n",
    "D2 = 3\n",
    "D3 = 8\n",
    "\n",
    "V1 = torch.rand(N, T, D1) #view 1\n",
    "V2 = torch.rand(N, T, D2) #view 2\n",
    "V3 = torch.rand(N, D3) #view 3 with different shape\n",
    "\n",
    "n_labels = 5\n",
    "labels = torch.randint(n_labels, size=(N,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b5630b",
   "metadata": {},
   "source": [
    "### Data Loader for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd90aa20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 2,\n",
       " 'views': {'view 1': tensor([[0.3920, 0.1860, 0.6681, 0.6972, 0.1608],\n",
       "          [0.8198, 0.2070, 0.5675, 0.1441, 0.2154],\n",
       "          [0.5397, 0.4983, 0.9102, 0.3904, 0.0326],\n",
       "          [0.4190, 0.0594, 0.8682, 0.2950, 0.0846],\n",
       "          [0.5797, 0.2838, 0.1169, 0.2154, 0.4877],\n",
       "          [0.9642, 0.2956, 0.0436, 0.2391, 0.8088],\n",
       "          [0.8173, 0.6105, 0.8034, 0.3139, 0.9064],\n",
       "          [0.8946, 0.9759, 0.0189, 0.4850, 0.1356],\n",
       "          [0.1933, 0.4255, 0.9371, 0.1092, 0.1856],\n",
       "          [0.0900, 0.6817, 0.9448, 0.8154, 0.9490],\n",
       "          [0.5480, 0.7739, 0.4531, 0.2991, 0.5934],\n",
       "          [0.4594, 0.9377, 0.8603, 0.6569, 0.8880]]),\n",
       "  'view 2': tensor([[0.7161, 0.4930, 0.9192],\n",
       "          [0.6086, 0.9001, 0.5389],\n",
       "          [0.1140, 0.5034, 0.3435],\n",
       "          [0.9101, 0.6852, 0.9498],\n",
       "          [0.1671, 0.8259, 0.6970],\n",
       "          [0.2079, 0.5667, 0.0768],\n",
       "          [0.8759, 0.7581, 0.0095],\n",
       "          [0.6717, 0.7768, 0.9993],\n",
       "          [0.2260, 0.4634, 0.7698],\n",
       "          [0.1033, 0.4592, 0.4683],\n",
       "          [0.6721, 0.1311, 0.0876],\n",
       "          [0.5398, 0.2582, 0.1021]]),\n",
       "  'view 3': tensor([0.3964, 0.1605, 0.1630, 0.2900, 0.2094, 0.5276, 0.4082, 0.2555])},\n",
       " 'target': tensor([0])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DataViews_torch(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_views: dict, target):\n",
    "        super(DataViews_torch,self).__init__()\n",
    "        self.target = target\n",
    "        self.view_names = list(input_views.keys())\n",
    "        self.views = [input_views[v_name] for v_name in self.view_names]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.views[0])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        target = self.target[index]\n",
    "        views = {view_n: view[index] for view, view_n in zip(self.views,self.view_names)}\n",
    "        \n",
    "        return {\"index\": index, \"views\": views, \"target\": target}\n",
    "\n",
    "train_dataset = DataViews_torch(input_views={\"view 1\": V1, \"view 2\": V2, \"view 3\": V3}, target=labels)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=32,drop_last=False,shuffle=True)\n",
    "\n",
    "train_dataset[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b904b811",
   "metadata": {},
   "source": [
    "### Model encoder, prediction head and merge function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68ac1c14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### MODEL\n",
    "from mvlearning.single.models import create_model\n",
    "from mvlearning.merge_module import MergeModule\n",
    "from mvlearning.utils import get_dic_emb_dims\n",
    "from mvlearning.fusion import FeatureFusion\n",
    "\n",
    "DIM_EMBEDDING = 32\n",
    "\n",
    "encoder_models = {}\n",
    "for name, inp_dim in {\"view 1\": D1, \"view 2\":D2}.items():\n",
    "    encoder_models[name] = create_model(inp_dim, DIM_EMBEDDING, model_type=\"lstm\")\n",
    "encoder_models[\"view 3\"] = create_model(D3, DIM_EMBEDDING, model_type=\"mlp\") #different model architecture\n",
    "\n",
    "EMBEDDING_DIC= get_dic_emb_dims(encoder_models)\n",
    "merge_function = MergeModule(EMBEDDING_DIC, mode=\"concat\")\n",
    "\n",
    "prediction_head = create_model(sum(EMBEDDING_DIC.values()), n_labels, model_type=\"mlp\", encoder=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2644a668",
   "metadata": {},
   "source": [
    "# Pure Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eb94e47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy tensor(0.1100)\n"
     ]
    }
   ],
   "source": [
    "## MODEL DEFINITION\n",
    "mv_model = FeatureFusion(encoder_models, merge_function, prediction_head)\n",
    "\n",
    "output_ = mv_model( {\"view 1\":V1, \"view 2\": V2, \"view 3\": V3})\n",
    "\n",
    "print(\"Accuracy\", torch.mean(((output_[\"prediction\"] > 0.5) == labels).to(torch.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b6be54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6202, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## LOSS FUNCTION AND OPTIMIZER\n",
    "optimizer = torch.optim.Adam(mv_model.parameters())\n",
    "loss_function=torch.nn.CrossEntropyLoss()\n",
    "\n",
    "loss_function(output_[\"prediction\"], torch.squeeze(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33630cf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1: with LOSS 1.5883548259735107:\n",
      "EPOCH 2: with LOSS 1.5919699668884277:\n",
      "EPOCH 3: with LOSS 1.5976487398147583:\n",
      "EPOCH 4: with LOSS 1.5683188438415527:\n",
      "EPOCH 5: with LOSS 1.570216417312622:\n",
      "EPOCH 6: with LOSS 1.5833370685577393:\n",
      "EPOCH 7: with LOSS 1.5634428262710571:\n",
      "EPOCH 8: with LOSS 1.5389440059661865:\n",
      "EPOCH 9: with LOSS 1.5715234279632568:\n",
      "EPOCH 10: with LOSS 1.5578805208206177:\n",
      "EPOCH 11: with LOSS 1.5528523921966553:\n",
      "EPOCH 12: with LOSS 1.5783663988113403:\n",
      "EPOCH 13: with LOSS 1.5555310249328613:\n",
      "EPOCH 14: with LOSS 1.551052451133728:\n",
      "EPOCH 15: with LOSS 1.5096633434295654:\n",
      "EPOCH 16: with LOSS 1.5071043968200684:\n",
      "EPOCH 17: with LOSS 1.5813878774642944:\n",
      "EPOCH 18: with LOSS 1.5382052659988403:\n",
      "EPOCH 19: with LOSS 1.5652226209640503:\n",
      "EPOCH 20: with LOSS 1.5213960409164429:\n",
      "EPOCH 21: with LOSS 1.5262451171875:\n",
      "EPOCH 22: with LOSS 1.5798885822296143:\n",
      "EPOCH 23: with LOSS 1.500242829322815:\n",
      "EPOCH 24: with LOSS 1.5035268068313599:\n",
      "EPOCH 25: with LOSS 1.5111453533172607:\n",
      "EPOCH 26: with LOSS 1.5253169536590576:\n",
      "EPOCH 27: with LOSS 1.4738409519195557:\n",
      "EPOCH 28: with LOSS 1.3976247310638428:\n",
      "EPOCH 29: with LOSS 1.4181445837020874:\n",
      "EPOCH 30: with LOSS 1.4380486011505127:\n",
      "EPOCH 31: with LOSS 1.4588936567306519:\n",
      "EPOCH 32: with LOSS 1.4486881494522095:\n",
      "EPOCH 33: with LOSS 1.4407689571380615:\n",
      "EPOCH 34: with LOSS 1.4071714878082275:\n",
      "EPOCH 35: with LOSS 1.403195858001709:\n",
      "EPOCH 36: with LOSS 1.3383535146713257:\n",
      "EPOCH 37: with LOSS 1.3055989742279053:\n",
      "EPOCH 38: with LOSS 1.3682944774627686:\n",
      "EPOCH 39: with LOSS 1.3208112716674805:\n",
      "EPOCH 40: with LOSS 1.3161243200302124:\n",
      "EPOCH 41: with LOSS 1.401366949081421:\n",
      "EPOCH 42: with LOSS 1.322843074798584:\n",
      "EPOCH 43: with LOSS 1.292102336883545:\n",
      "EPOCH 44: with LOSS 1.3558828830718994:\n",
      "EPOCH 45: with LOSS 1.2652912139892578:\n",
      "EPOCH 46: with LOSS 1.379029393196106:\n",
      "EPOCH 47: with LOSS 1.3102364540100098:\n",
      "EPOCH 48: with LOSS 1.208099603652954:\n",
      "EPOCH 49: with LOSS 1.180253505706787:\n",
      "EPOCH 50: with LOSS 1.2671409845352173:\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    mv_model.train(True)\n",
    "    running_loss = 0.\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = mv_model(data[\"views\"])\n",
    "        loss = loss_function(outputs[\"prediction\"], torch.squeeze(data[\"target\"]))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "    print('EPOCH {}: with LOSS {}:'.format(epoch + 1, running_loss/len(train_dataloader)))\n",
    "\n",
    "    ## VALIDATION/EARLY STOPPING IF REQUIRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02da705b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy tensor(0.1360)\n"
     ]
    }
   ],
   "source": [
    "output_ = mv_model( {\"view 1\":V1, \"view 2\": V2, \"view 3\": V3})\n",
    "\n",
    "print(\"Accuracy\", torch.mean(((output_[\"prediction\"] > 0.5) == labels).to(torch.float32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93713659",
   "metadata": {},
   "source": [
    "# Using Pytorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cff5e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "## MODEL DEFINITION with LOSS FUNCTION and OPTIMIZER INSIDE\n",
    "mv_model = FeatureFusion(encoder_models, merge_function, prediction_head, \n",
    "                         loss_function=torch.nn.CrossEntropyLoss(), optimizer=\"adam\")\n",
    "\n",
    "mv_model.configure_optimizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "527d849f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': tensor(1.6020, grad_fn=<NllLossBackward0>)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv_model.loss_batch({\n",
    "    \"views\": {\"view 1\":V1, \"view 2\": V2, \"view 3\": V3},\n",
    "    \"target\": labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcf47046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy tensor(0.1100)\n"
     ]
    }
   ],
   "source": [
    "output_ = mv_model( {\"view 1\":V1, \"view 2\": V2, \"view 3\": V3})\n",
    "\n",
    "print(\"Accuracy\", torch.mean(((output_[\"prediction\"] > 0.5) == labels).to(torch.float32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e887a91",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f860da19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/panshop/anaconda3/envs/views/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:133: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type             | Params\n",
      "-----------------------------------------------------\n",
      "0 | views_encoder   | ModuleDict       | 431 K \n",
      "1 | merge_module    | MergeModule      | 0     \n",
      "2 | prediction_head | Generic_Decoder  | 29.6 K\n",
      "3 | loss_function   | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------------\n",
      "461 K     Trainable params\n",
      "0         Non-trainable params\n",
      "461 K     Total params\n",
      "1.844     Total estimated model params size (MB)\n",
      "/home/panshop/anaconda3/envs/views/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/panshop/anaconda3/envs/views/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1933: PossibleUserWarning: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12fcb925ce24d0aa721a3b7dff07961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=50, accelerator=\"gpu\", devices = 1)\n",
    "trainer.fit(mv_model, train_dataloader, val_dataloaders=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76810f3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy tensor(0.1400)\n"
     ]
    }
   ],
   "source": [
    "output_ = mv_model( {\"view 1\":V1, \"view 2\": V2, \"view 3\": V3})\n",
    "\n",
    "print(\"Accuracy\", torch.mean(((output_[\"prediction\"] > 0.5) == labels).to(torch.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a127339",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:views]",
   "language": "python",
   "name": "conda-env-views-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
