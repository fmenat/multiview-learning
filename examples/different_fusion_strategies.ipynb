{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8577622",
   "metadata": {},
   "source": [
    "# Examples of different fusion strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18580e5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "N = 100\n",
    "T = 12\n",
    "\n",
    "D1 = 5\n",
    "D2 = 3\n",
    "D3 = 8\n",
    "\n",
    "V1 = torch.rand(N, T, D1) #view 1\n",
    "V2 = torch.rand(N, T, D2) #view 2\n",
    "V3 = torch.rand(N, D3) #view 3 with different shape\n",
    "\n",
    "n_labels = 5\n",
    "labels = torch.randint(n_labels, size=(N,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812b3f4c",
   "metadata": {},
   "source": [
    "## Input Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e89726f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Generic_Encoder(\n",
       "    (pre_encoder): RNNet(\n",
       "      (rnn): LSTM(8, 128, num_layers=2, batch_first=True)\n",
       "      (fc): Sequential(\n",
       "        (0): Identity()\n",
       "      )\n",
       "    )\n",
       "    (linear_layer): Linear(in_features=128, out_features=32, bias=True)\n",
       "    (normalization_layer): Identity()\n",
       "  )\n",
       "  (1): Generic_Decoder(\n",
       "    (pre_decoder): MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Identity()\n",
       "          (3): Identity()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Identity()\n",
       "          (3): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear_layer): Linear(in_features=128, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mvlearning.single.models import create_model\n",
    "\n",
    "TOTAL_DIMS_STACKED = D1+D2\n",
    "DIM_EMBEDDING = 32\n",
    "\n",
    "encoder_model = create_model(TOTAL_DIMS_STACKED, DIM_EMBEDDING, model_type=\"lstm\")\n",
    "prediction_head = create_model(DIM_EMBEDDING, n_labels, model_type=\"mlp\", encoder=False)\n",
    "full_model = torch.nn.Sequential(encoder_model, prediction_head)\n",
    "full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70123ed6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InputFusion(\n",
       "  (views_encoder): ModuleDict(\n",
       "    (view 1): Identity()\n",
       "    (view 2): Identity()\n",
       "  )\n",
       "  (merge_module): MergeModule(\n",
       "    (concater_function): Concatenate_()\n",
       "  )\n",
       "  (prediction_head): Sequential(\n",
       "    (0): Generic_Encoder(\n",
       "      (pre_encoder): RNNet(\n",
       "        (rnn): LSTM(8, 128, num_layers=2, batch_first=True)\n",
       "        (fc): Sequential(\n",
       "          (0): Identity()\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Linear(in_features=128, out_features=32, bias=True)\n",
       "      (normalization_layer): Identity()\n",
       "    )\n",
       "    (1): Generic_Decoder(\n",
       "      (pre_decoder): MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Identity()\n",
       "            (3): Identity()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Identity()\n",
       "            (3): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Linear(in_features=128, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mvlearning.fusion import InputFusion\n",
    "\n",
    "mv_model = InputFusion(full_model, view_names=[\"view 1\", \"view 2\"])\n",
    "mv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "142b05e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': torch.Size([100, 5])}\n",
      "views:rep ----\n",
      "{'view 1': torch.Size([100, 12, 5])}\n",
      "{'view 2': torch.Size([100, 12, 3])}\n",
      "{'joint_rep': torch.Size([100, 12, 8])}\n"
     ]
    }
   ],
   "source": [
    "output_ = mv_model( {\"view 1\":V1, \"view 2\": V2})\n",
    "\n",
    "for k,v in output_.items():\n",
    "    if type(v) == dict:\n",
    "        print(k, \"----\")\n",
    "        for k_, v_ in v.items():\n",
    "            print({k_: v_.size()})\n",
    "    else:\n",
    "        print({k: v.size()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fc72acc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': tensor(1.6172, grad_fn=<NllLossBackward0>)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv_model = InputFusion(full_model, view_names=[\"view 1\", \"view 2\"], loss_function=torch.nn.CrossEntropyLoss())\n",
    "mv_model.loss_batch({\n",
    "    \"views\": {\"view 1\":V1, \"view 2\": V2},\n",
    "    \"target\": labels\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1b525b",
   "metadata": {},
   "source": [
    "## Decision Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "764bc655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['view 1', 'view 2', 'view 3'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mvlearning.single.models import create_model\n",
    "\n",
    "DIM_EMBEDDING = 32\n",
    "\n",
    "\n",
    "prediction_models= {}\n",
    "for name, inp_dim in {\"view 1\": D1, \"view 2\":D2}.items():\n",
    "    encoder_model = create_model(inp_dim, DIM_EMBEDDING, model_type=\"lstm\")\n",
    "    prediction_head = create_model(DIM_EMBEDDING, n_labels, model_type=\"mlp\", encoder=False)\n",
    "    prediction_models[name] = torch.nn.Sequential(encoder_model, prediction_head)\n",
    "\n",
    "encoder_model = create_model(D3, DIM_EMBEDDING, model_type=\"mlp\") #different model architecture\n",
    "prediction_head = create_model(DIM_EMBEDDING, n_labels, model_type=\"mlp\", encoder=False)\n",
    "prediction_models[\"view 3\"] = torch.nn.Sequential(encoder_model, prediction_head)\n",
    "\n",
    "prediction_models.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "734083d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionFusion(\n",
       "  (views_encoder): ModuleDict(\n",
       "    (view 1): Sequential(\n",
       "      (0): Generic_Encoder(\n",
       "        (pre_encoder): RNNet(\n",
       "          (rnn): LSTM(5, 128, num_layers=2, batch_first=True)\n",
       "          (fc): Sequential(\n",
       "            (0): Identity()\n",
       "          )\n",
       "        )\n",
       "        (linear_layer): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (normalization_layer): Identity()\n",
       "      )\n",
       "      (1): Generic_Decoder(\n",
       "        (pre_decoder): MLP(\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Identity()\n",
       "              (3): Identity()\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Identity()\n",
       "              (3): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (linear_layer): Linear(in_features=128, out_features=5, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (view 2): Sequential(\n",
       "      (0): Generic_Encoder(\n",
       "        (pre_encoder): RNNet(\n",
       "          (rnn): LSTM(3, 128, num_layers=2, batch_first=True)\n",
       "          (fc): Sequential(\n",
       "            (0): Identity()\n",
       "          )\n",
       "        )\n",
       "        (linear_layer): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (normalization_layer): Identity()\n",
       "      )\n",
       "      (1): Generic_Decoder(\n",
       "        (pre_decoder): MLP(\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Identity()\n",
       "              (3): Identity()\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Identity()\n",
       "              (3): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (linear_layer): Linear(in_features=128, out_features=5, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (view 3): Sequential(\n",
       "      (0): Generic_Encoder(\n",
       "        (pre_encoder): MLP(\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=8, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Identity()\n",
       "              (3): Identity()\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Identity()\n",
       "              (3): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (linear_layer): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (normalization_layer): Identity()\n",
       "      )\n",
       "      (1): Generic_Decoder(\n",
       "        (pre_decoder): MLP(\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Identity()\n",
       "              (3): Identity()\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Identity()\n",
       "              (3): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (linear_layer): Linear(in_features=128, out_features=5, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (merge_module): MergeModule(\n",
       "    (stacker_function): Stacking_()\n",
       "    (pooler_function): UniformSum_()\n",
       "  )\n",
       "  (prediction_head): Lambda()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mvlearning.fusion import DecisionFusion\n",
    "\n",
    "mv_model = DecisionFusion(prediction_models) #just take the avg\n",
    "mv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be860182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': torch.Size([100, 5])}\n",
      "views:rep ----\n",
      "{'view 1': torch.Size([100, 5])}\n",
      "{'view 2': torch.Size([100, 5])}\n",
      "{'view 3': torch.Size([100, 5])}\n",
      "{'joint_rep': torch.Size([100, 5])}\n"
     ]
    }
   ],
   "source": [
    "output_ = mv_model( {\"view 1\":V1, \"view 2\": V2, \"view 3\": V3})\n",
    "for k,v in output_.items():\n",
    "    if type(v) == dict:\n",
    "        print(k, \"----\")\n",
    "        for k_, v_ in v.items():\n",
    "            print({k_: v_.size()})\n",
    "    else:\n",
    "        print({k: v.size()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "884daced",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': tensor(1.6142, grad_fn=<NllLossBackward0>)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv_model = DecisionFusion(prediction_models, loss_function=torch.nn.CrossEntropyLoss())\n",
    "mv_model.loss_batch({\n",
    "    \"views\": {\"view 1\":V1, \"view 2\": V2, \"view 3\": V3},\n",
    "    \"target\": labels\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6748c71c",
   "metadata": {},
   "source": [
    "### Including Multi-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe8b8b0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionFusionMultiLoss(\n",
       "  (views_encoder): ModuleDict(\n",
       "    (view 1): Sequential(\n",
       "      (0): Generic_Encoder(\n",
       "        (pre_encoder): RNNet(\n",
       "          (rnn): LSTM(5, 128, num_layers=2, batch_first=True)\n",
       "          (fc): Sequential(\n",
       "            (0): Identity()\n",
       "          )\n",
       "        )\n",
       "        (linear_layer): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (normalization_layer): Identity()\n",
       "      )\n",
       "      (1): Generic_Decoder(\n",
       "        (pre_decoder): MLP(\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Identity()\n",
       "              (3): Identity()\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Identity()\n",
       "              (3): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (linear_layer): Linear(in_features=128, out_features=5, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (view 2): Sequential(\n",
       "      (0): Generic_Encoder(\n",
       "        (pre_encoder): RNNet(\n",
       "          (rnn): LSTM(3, 128, num_layers=2, batch_first=True)\n",
       "          (fc): Sequential(\n",
       "            (0): Identity()\n",
       "          )\n",
       "        )\n",
       "        (linear_layer): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (normalization_layer): Identity()\n",
       "      )\n",
       "      (1): Generic_Decoder(\n",
       "        (pre_decoder): MLP(\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Identity()\n",
       "              (3): Identity()\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Identity()\n",
       "              (3): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (linear_layer): Linear(in_features=128, out_features=5, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (view 3): Sequential(\n",
       "      (0): Generic_Encoder(\n",
       "        (pre_encoder): MLP(\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=8, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Identity()\n",
       "              (3): Identity()\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Identity()\n",
       "              (3): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (linear_layer): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (normalization_layer): Identity()\n",
       "      )\n",
       "      (1): Generic_Decoder(\n",
       "        (pre_decoder): MLP(\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Identity()\n",
       "              (3): Identity()\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Identity()\n",
       "              (3): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (linear_layer): Linear(in_features=128, out_features=5, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (merge_module): MergeModule(\n",
       "    (stacker_function): Stacking_()\n",
       "    (pooler_function): UniformSum_()\n",
       "  )\n",
       "  (prediction_head): Lambda()\n",
       "  (loss_function): CrossEntropyLoss()\n",
       "  (aux_predictor_base): Lambda()\n",
       "  (aux_predictor): ModuleDict(\n",
       "    (view 1): Lambda()\n",
       "    (view 2): Lambda()\n",
       "    (view 3): Lambda()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mvlearning.fusion import DecisionFusionMultiLoss\n",
    "mv_model = DecisionFusionMultiLoss(prediction_models,loss_function=torch.nn.CrossEntropyLoss(), multiloss_weights=3)\n",
    "mv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be1a8ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': tensor(6.4609, grad_fn=<AddBackward0>),\n",
       " 'lossmain': tensor(1.6142, grad_fn=<NllLossBackward0>),\n",
       " 'lossaux': tensor(14.5401, grad_fn=<AddBackward0>),\n",
       " 'lossview 1': tensor(4.8643, grad_fn=<MulBackward0>),\n",
       " 'lossview 2': tensor(4.8399, grad_fn=<MulBackward0>),\n",
       " 'lossview 3': tensor(4.8358, grad_fn=<MulBackward0>)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv_model.loss_batch({\n",
    "    \"views\": {\"view 1\":V1, \"view 2\": V2, \"view 3\": V3},\n",
    "    \"target\": labels\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0b6a33",
   "metadata": {},
   "source": [
    "## Feature Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5415b86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['view 1', 'view 2', 'view 3'])\n",
      "{'view 1': 32, 'view 2': 32, 'view 3': 32}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MergeModule(\n",
       "  (concater_function): Concatenate_()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mvlearning.single.models import create_model\n",
    "from mvlearning.merge_module import MergeModule\n",
    "from mvlearning.utils import get_dic_emb_dims\n",
    "\n",
    "DIM_EMBEDDING = 32\n",
    "\n",
    "encoder_models = {}\n",
    "for name, inp_dim in {\"view 1\": D1, \"view 2\":D2}.items():\n",
    "    encoder_models[name] = create_model(inp_dim, DIM_EMBEDDING, model_type=\"lstm\")\n",
    "encoder_models[\"view 3\"] = create_model(D3, DIM_EMBEDDING, model_type=\"mlp\") #different model architecture\n",
    "print(encoder_models.keys())\n",
    "\n",
    "EMBEDDING_DIC= get_dic_emb_dims(encoder_models)\n",
    "print(EMBEDDING_DIC)\n",
    "merge_function = MergeModule(EMBEDDING_DIC, mode=\"concat\")\n",
    "\n",
    "prediction_head = create_model(sum(EMBEDDING_DIC.values()), n_labels, model_type=\"mlp\", encoder=False)\n",
    "\n",
    "merge_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e55bb3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureFusion(\n",
       "  (views_encoder): ModuleDict(\n",
       "    (view 1): Generic_Encoder(\n",
       "      (pre_encoder): RNNet(\n",
       "        (rnn): LSTM(5, 128, num_layers=2, batch_first=True)\n",
       "        (fc): Sequential(\n",
       "          (0): Identity()\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Linear(in_features=128, out_features=32, bias=True)\n",
       "      (normalization_layer): Identity()\n",
       "    )\n",
       "    (view 2): Generic_Encoder(\n",
       "      (pre_encoder): RNNet(\n",
       "        (rnn): LSTM(3, 128, num_layers=2, batch_first=True)\n",
       "        (fc): Sequential(\n",
       "          (0): Identity()\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Linear(in_features=128, out_features=32, bias=True)\n",
       "      (normalization_layer): Identity()\n",
       "    )\n",
       "    (view 3): Generic_Encoder(\n",
       "      (pre_encoder): MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Identity()\n",
       "            (3): Identity()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Identity()\n",
       "            (3): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Linear(in_features=128, out_features=32, bias=True)\n",
       "      (normalization_layer): Identity()\n",
       "    )\n",
       "  )\n",
       "  (merge_module): MergeModule(\n",
       "    (concater_function): Concatenate_()\n",
       "  )\n",
       "  (prediction_head): Generic_Decoder(\n",
       "    (pre_decoder): MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=96, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Identity()\n",
       "          (3): Identity()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Identity()\n",
       "          (3): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear_layer): Linear(in_features=128, out_features=5, bias=True)\n",
       "  )\n",
       "  (loss_function): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mvlearning.fusion import FeatureFusion\n",
    "\n",
    "mv_model = FeatureFusion(encoder_models, merge_function, prediction_head, loss_function=torch.nn.CrossEntropyLoss())\n",
    "mv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "773677fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': torch.Size([100, 5])}\n",
      "views:rep ----\n",
      "{'view 1': torch.Size([100, 32])}\n",
      "{'view 2': torch.Size([100, 32])}\n",
      "{'view 3': torch.Size([100, 32])}\n",
      "{'joint_rep': torch.Size([100, 96])}\n"
     ]
    }
   ],
   "source": [
    "output_ = mv_model( {\"view 1\":V1, \"view 2\": V2, \"view 3\": V3})\n",
    "for k,v in output_.items():\n",
    "    if type(v) == dict:\n",
    "        print(k, \"----\")\n",
    "        for k_, v_ in v.items():\n",
    "            print({k_: v_.size()})\n",
    "    else:\n",
    "        print({k: v.size()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e97b265f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': tensor(1.6117, grad_fn=<NllLossBackward0>)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv_model.loss_batch({\n",
    "    \"views\": {\"view 1\":V1, \"view 2\": V2, \"view 3\": V3},\n",
    "    \"target\": labels\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b555598",
   "metadata": {},
   "source": [
    "### Pooling fusion modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46e47e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_head = create_model(DIM_EMBEDDING, n_labels, model_type=\"mlp\", encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "942f942c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': torch.Size([100, 5])}\n",
      "views:rep ----\n",
      "{'view 1': torch.Size([100, 32])}\n",
      "{'view 2': torch.Size([100, 32])}\n",
      "{'view 3': torch.Size([100, 32])}\n",
      "{'joint_rep': torch.Size([100, 96])}\n"
     ]
    }
   ],
   "source": [
    "merge_function = MergeModule(EMBEDDING_DIC, mode=\"avg\")\n",
    "mv_model = FeatureFusion(encoder_models, merge_function, prediction_head, loss_function=torch.nn.CrossEntropyLoss())\n",
    "\n",
    "for k,v in output_.items():\n",
    "    if type(v) == dict:\n",
    "        print(k, \"----\")\n",
    "        for k_, v_ in v.items():\n",
    "            print({k_: v_.size()})\n",
    "    else:\n",
    "        print({k: v.size()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03d43c27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': torch.Size([100, 5])}\n",
      "views:rep ----\n",
      "{'view 1': torch.Size([100, 32])}\n",
      "{'view 2': torch.Size([100, 32])}\n",
      "{'view 3': torch.Size([100, 32])}\n",
      "{'joint_rep': torch.Size([100, 32])}\n",
      "{'att_views': torch.Size([100, 3, 1])}\n"
     ]
    }
   ],
   "source": [
    "merge_function = MergeModule(EMBEDDING_DIC, mode=\"concat\", adaptive=True, features=False)\n",
    "\n",
    "mv_model = FeatureFusion(encoder_models, merge_function, prediction_head)\n",
    "\n",
    "output_ = mv_model( {\"view 1\":V1, \"view 2\": V2, \"view 3\": V3})\n",
    "for k,v in output_.items():\n",
    "    if type(v) == dict:\n",
    "        print(k, \"----\")\n",
    "        for k_, v_ in v.items():\n",
    "            print({k_: v_.size()})\n",
    "    else:\n",
    "        print({k: v.size()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8db20ce",
   "metadata": {},
   "source": [
    "### Including Multi-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54acb5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureFusionMultiLoss(\n",
       "  (views_encoder): ModuleDict(\n",
       "    (view 1): Generic_Encoder(\n",
       "      (pre_encoder): RNNet(\n",
       "        (rnn): LSTM(5, 128, num_layers=2, batch_first=True)\n",
       "        (fc): Sequential(\n",
       "          (0): Identity()\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Linear(in_features=128, out_features=32, bias=True)\n",
       "      (normalization_layer): Identity()\n",
       "    )\n",
       "    (view 2): Generic_Encoder(\n",
       "      (pre_encoder): RNNet(\n",
       "        (rnn): LSTM(3, 128, num_layers=2, batch_first=True)\n",
       "        (fc): Sequential(\n",
       "          (0): Identity()\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Linear(in_features=128, out_features=32, bias=True)\n",
       "      (normalization_layer): Identity()\n",
       "    )\n",
       "    (view 3): Generic_Encoder(\n",
       "      (pre_encoder): MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Identity()\n",
       "            (3): Identity()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Identity()\n",
       "            (3): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Linear(in_features=128, out_features=32, bias=True)\n",
       "      (normalization_layer): Identity()\n",
       "    )\n",
       "  )\n",
       "  (merge_module): MergeModule(\n",
       "    (stacker_function): Stacking_()\n",
       "    (concater_function): Concatenate_()\n",
       "    (attention_function): Linear(in_features=96, out_features=3, bias=True)\n",
       "  )\n",
       "  (prediction_head): Generic_Decoder(\n",
       "    (pre_decoder): MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Identity()\n",
       "          (3): Identity()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Identity()\n",
       "          (3): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear_layer): Linear(in_features=128, out_features=5, bias=True)\n",
       "  )\n",
       "  (loss_function): CrossEntropyLoss()\n",
       "  (aux_predictor_base): Generic_Decoder(\n",
       "    (pre_decoder): MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Identity()\n",
       "          (3): Identity()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Identity()\n",
       "          (3): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear_layer): Linear(in_features=128, out_features=5, bias=True)\n",
       "  )\n",
       "  (aux_predictor): ModuleDict(\n",
       "    (view 1): Generic_Decoder(\n",
       "      (pre_decoder): MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Identity()\n",
       "            (3): Identity()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Identity()\n",
       "            (3): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Linear(in_features=128, out_features=5, bias=True)\n",
       "    )\n",
       "    (view 2): Generic_Decoder(\n",
       "      (pre_decoder): MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Identity()\n",
       "            (3): Identity()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Identity()\n",
       "            (3): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Linear(in_features=128, out_features=5, bias=True)\n",
       "    )\n",
       "    (view 3): Generic_Decoder(\n",
       "      (pre_decoder): MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Identity()\n",
       "            (3): Identity()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Identity()\n",
       "            (3): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Linear(in_features=128, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mvlearning.fusion import FeatureFusionMultiLoss\n",
    "\n",
    "mv_model = FeatureFusionMultiLoss(encoder_models, merge_function, prediction_head, loss_function=torch.nn.CrossEntropyLoss(),\n",
    "                                  multiloss_weights={\"view 1\": 1, \"view 2\": 0 , \"view 3\": 0.1})\n",
    "mv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29c40ca6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': tensor(2.2039, grad_fn=<AddBackward0>),\n",
       " 'lossmain': tensor(1.6128, grad_fn=<NllLossBackward0>),\n",
       " 'lossaux': tensor(1.7733, grad_fn=<AddBackward0>),\n",
       " 'lossview 1': tensor(1.6120, grad_fn=<MulBackward0>),\n",
       " 'lossview 3': tensor(0.1612, grad_fn=<MulBackward0>)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv_model.loss_batch({\n",
    "    \"views\": {\"view 1\":V1, \"view 2\": V2, \"view 3\": V3},\n",
    "    \"target\": labels\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f6168c",
   "metadata": {},
   "source": [
    "## Hybrid Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2bb7b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['view 1', 'view 2', 'view 3'])\n",
      "{'view 1': 32, 'view 2': 32, 'view 3': 32}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MergeModule(\n",
       "  (stacker_function): Stacking_()\n",
       "  (concater_function): Concatenate_()\n",
       "  (attention_function): Linear(in_features=96, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mvlearning.single.models import create_model\n",
    "from mvlearning.merge_module import MergeModule\n",
    "from mvlearning.utils import get_dic_emb_dims\n",
    "\n",
    "DIM_EMBEDDING = 32\n",
    "\n",
    "encoder_models = {}\n",
    "for name, inp_dim in {\"view 1\": D1, \"view 2\":D2}.items():\n",
    "    encoder_models[name] = create_model(inp_dim, DIM_EMBEDDING, model_type=\"lstm\")\n",
    "encoder_models[\"view 3\"] = create_model(D3, DIM_EMBEDDING, model_type=\"mlp\") #different model architecture\n",
    "print(encoder_models.keys())\n",
    "\n",
    "EMBEDDING_DIC= get_dic_emb_dims(encoder_models)\n",
    "print(EMBEDDING_DIC)\n",
    "\n",
    "\n",
    "merge_function = MergeModule(EMBEDDING_DIC, mode=\"concat\", adaptive=True, features=False)\n",
    "prediction_head = create_model(DIM_EMBEDDING, n_labels, model_type=\"mlp\", encoder=False)\n",
    "\n",
    "#fusion_module = MergeModule(EMBEDDING_DIC, mode=\"concat\")\n",
    "#prediction_head = create_model(sum(EMBEDDING_DIC.values()), n_labels, model_type=\"mlp\", encoder=False)\n",
    "\n",
    "merge_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b875e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HybridFusion_FD(\n",
       "  (views_encoder): ModuleDict(\n",
       "    (view 1): Generic_Encoder(\n",
       "      (pre_encoder): RNNet(\n",
       "        (rnn): LSTM(5, 128, num_layers=2, batch_first=True)\n",
       "        (fc): Sequential(\n",
       "          (0): Identity()\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Linear(in_features=128, out_features=32, bias=True)\n",
       "      (normalization_layer): Identity()\n",
       "    )\n",
       "    (view 2): Generic_Encoder(\n",
       "      (pre_encoder): RNNet(\n",
       "        (rnn): LSTM(3, 128, num_layers=2, batch_first=True)\n",
       "        (fc): Sequential(\n",
       "          (0): Identity()\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Linear(in_features=128, out_features=32, bias=True)\n",
       "      (normalization_layer): Identity()\n",
       "    )\n",
       "    (view 3): Generic_Encoder(\n",
       "      (pre_encoder): MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=8, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Identity()\n",
       "            (3): Identity()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Identity()\n",
       "            (3): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Linear(in_features=128, out_features=32, bias=True)\n",
       "      (normalization_layer): Identity()\n",
       "    )\n",
       "  )\n",
       "  (merge_module): MergeModule(\n",
       "    (stacker_function): Stacking_()\n",
       "    (concater_function): Concatenate_()\n",
       "    (attention_function): Linear(in_features=96, out_features=3, bias=True)\n",
       "  )\n",
       "  (prediction_head): Generic_Decoder(\n",
       "    (pre_decoder): MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Identity()\n",
       "          (3): Identity()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Identity()\n",
       "          (3): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear_layer): Linear(in_features=128, out_features=5, bias=True)\n",
       "  )\n",
       "  (loss_function): CrossEntropyLoss()\n",
       "  (aux_predictor_base): Generic_Decoder(\n",
       "    (pre_decoder): MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Identity()\n",
       "          (3): Identity()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Identity()\n",
       "          (3): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear_layer): Linear(in_features=128, out_features=5, bias=True)\n",
       "  )\n",
       "  (aux_predictor): ModuleDict(\n",
       "    (view 1): Generic_Decoder(\n",
       "      (pre_decoder): MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Identity()\n",
       "            (3): Identity()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Identity()\n",
       "            (3): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Linear(in_features=128, out_features=5, bias=True)\n",
       "    )\n",
       "    (view 2): Generic_Decoder(\n",
       "      (pre_decoder): MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Identity()\n",
       "            (3): Identity()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Identity()\n",
       "            (3): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Linear(in_features=128, out_features=5, bias=True)\n",
       "    )\n",
       "    (view 3): Generic_Decoder(\n",
       "      (pre_decoder): MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Identity()\n",
       "            (3): Identity()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Identity()\n",
       "            (3): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (linear_layer): Linear(in_features=128, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mvlearning.fusion import HybridFusion_FD\n",
    "\n",
    "mv_model = HybridFusion_FD(encoder_models, merge_function, prediction_head, loss_function=torch.nn.CrossEntropyLoss())\n",
    "mv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f031025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "views:rep ----\n",
      "{'view 1': torch.Size([100, 32])}\n",
      "{'view 2': torch.Size([100, 32])}\n",
      "{'view 3': torch.Size([100, 32])}\n",
      "{'joint_rep': torch.Size([100, 32])}\n",
      "{'att_views': torch.Size([100, 3, 1])}\n",
      "views:prediction ----\n",
      "{'view 1': torch.Size([100, 5])}\n",
      "{'view 2': torch.Size([100, 5])}\n",
      "{'view 3': torch.Size([100, 5])}\n",
      "fusion:prediction ----\n",
      "{'feat': torch.Size([100, 5])}\n",
      "{'dec': torch.Size([100, 5])}\n",
      "{'prediction': torch.Size([100, 5])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'objective': tensor(1.6100, grad_fn=<AddBackward0>),\n",
       " 'lossmain': tensor(1.6100, grad_fn=<NllLossBackward0>),\n",
       " 'lossaux': 0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ = mv_model( {\"view 1\":V1, \"view 2\": V2, \"view 3\": V3})\n",
    "for k,v in output_.items():\n",
    "    if type(v) == dict:\n",
    "        print(k, \"----\")\n",
    "        for k_, v_ in v.items():\n",
    "            print({k_: v_.size()})\n",
    "    else:\n",
    "        print({k: v.size()})\n",
    "        \n",
    "mv_model.loss_batch({\n",
    "    \"views\": {\"view 1\":V1, \"view 2\": V2, \"view 3\": V3},\n",
    "    \"target\": labels\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2e8bc3",
   "metadata": {},
   "source": [
    "## Ensemble aggregation\n",
    "> or pooling of single-view models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc9b1d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['view 1', 'view 2', 'view 3'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mvlearning.single.models import create_model\n",
    "\n",
    "DIM_EMBEDDING = 32\n",
    "\n",
    "prediction_models= {}\n",
    "for name, inp_dim in {\"view 1\": D1, \"view 2\":D2}.items():\n",
    "    encoder_model = create_model(inp_dim, DIM_EMBEDDING, model_type=\"lstm\")\n",
    "    prediction_head = create_model(DIM_EMBEDDING, n_labels, model_type=\"mlp\", encoder=False)\n",
    "    prediction_models[name] = torch.nn.Sequential(encoder_model, prediction_head)\n",
    "\n",
    "encoder_model = create_model(D3, DIM_EMBEDDING, model_type=\"mlp\") #different model architecture\n",
    "prediction_head = create_model(DIM_EMBEDDING, n_labels, model_type=\"mlp\", encoder=False)\n",
    "prediction_models[\"view 3\"] = torch.nn.Sequential(encoder_model, prediction_head)\n",
    "\n",
    "prediction_models.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c2894f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleViewPool(\n",
       "  (views_encoder): ModuleDict(\n",
       "    (view 1): Sequential(\n",
       "      (0): Generic_Encoder(\n",
       "        (pre_encoder): RNNet(\n",
       "          (rnn): LSTM(5, 128, num_layers=2, batch_first=True)\n",
       "          (fc): Sequential(\n",
       "            (0): Identity()\n",
       "          )\n",
       "        )\n",
       "        (linear_layer): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (normalization_layer): Identity()\n",
       "      )\n",
       "      (1): Generic_Decoder(\n",
       "        (pre_decoder): MLP(\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Identity()\n",
       "              (3): Identity()\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Identity()\n",
       "              (3): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (linear_layer): Linear(in_features=128, out_features=5, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (view 2): Sequential(\n",
       "      (0): Generic_Encoder(\n",
       "        (pre_encoder): RNNet(\n",
       "          (rnn): LSTM(3, 128, num_layers=2, batch_first=True)\n",
       "          (fc): Sequential(\n",
       "            (0): Identity()\n",
       "          )\n",
       "        )\n",
       "        (linear_layer): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (normalization_layer): Identity()\n",
       "      )\n",
       "      (1): Generic_Decoder(\n",
       "        (pre_decoder): MLP(\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Identity()\n",
       "              (3): Identity()\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Identity()\n",
       "              (3): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (linear_layer): Linear(in_features=128, out_features=5, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (view 3): Sequential(\n",
       "      (0): Generic_Encoder(\n",
       "        (pre_encoder): MLP(\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=8, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Identity()\n",
       "              (3): Identity()\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Identity()\n",
       "              (3): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (linear_layer): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (normalization_layer): Identity()\n",
       "      )\n",
       "      (1): Generic_Decoder(\n",
       "        (pre_decoder): MLP(\n",
       "          (layers): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Identity()\n",
       "              (3): Identity()\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Identity()\n",
       "              (3): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (linear_layer): Linear(in_features=128, out_features=5, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (merge_module): Identity()\n",
       "  (prediction_head): Identity()\n",
       "  (loss_function): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mvlearning.fusion import SingleViewPool\n",
    "\n",
    "mv_model = SingleViewPool(prediction_models, loss_function=torch.nn.CrossEntropyLoss())\n",
    "mv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55c87d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "views:prediction ----\n",
      "{'view 1': torch.Size([100, 5])}\n",
      "{'view 2': torch.Size([100, 5])}\n",
      "{'view 3': torch.Size([100, 5])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'objective': tensor(4.8503, grad_fn=<AddBackward0>),\n",
       " 'lossview 1': tensor(1.6117, grad_fn=<NllLossBackward0>),\n",
       " 'lossview 2': tensor(1.6145, grad_fn=<NllLossBackward0>),\n",
       " 'lossview 3': tensor(1.6241, grad_fn=<NllLossBackward0>)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ = mv_model( {\"view 1\":V1, \"view 2\": V2, \"view 3\": V3})\n",
    "for k,v in output_.items():\n",
    "    if type(v) == dict:\n",
    "        print(k, \"----\")\n",
    "        for k_, v_ in v.items():\n",
    "            print({k_: v_.size()})\n",
    "    else:\n",
    "        print({k: v.size()})\n",
    "        \n",
    "mv_model.loss_batch({\n",
    "    \"views\": {\"view 1\":V1, \"view 2\": V2, \"view 3\": V3},\n",
    "    \"target\": labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b6e82b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:views]",
   "language": "python",
   "name": "conda-env-views-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "300px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
